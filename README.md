# Store Sales Time Series Forecasting

## プロジェクト概要（サマリー）

* **課題**：店舗 × 商品カテゴリごとの日次販売数を16日先まで予測
* **手法**：LightGBM を中心とした時系列回帰モデル
* **工夫点**：時系列交差検証の設計、リーク防止の特徴量設計、CNN embedding の検証
* **最終スコア（Public LB）**：

  * 単一モデル：0.42405
  * **アンサンブル：0.41542**
* **順位**：**96 / 793（上位 約12%）**

本プロジェクトでは、精度向上だけでなく、**再現性・妥当性・意思決定プロセス**を重視したモデリングを行った。

---

## 概要

本リポジトリは、Kaggle コンペティション **Store Sales - Time Series Forecasting** に対する解法をまとめたものである。
目的は、過去の販売実績および補助的な外部データを用いて、
各 *店舗 × 商品カテゴリ* ごとの日次販売数を予測することである。

本プロジェクトでは、

* **時系列に配慮した交差検証**
* **リークを防ぐ特徴量設計**
* **定量的な検証に基づくモデル選択**

を重視し、Leaderboard 上のテクニックに依存しない実装を行った。

---

## 結果

* **最終単一モデル（Public LB）**：0.42405
* **アンサンブルモデル（Public LB）**：**0.41542**
* **順位**：**96 / 793 人（上位 約12%）**

アンサンブルモデルは単一モデルを一貫して上回り、
交差検証と Public Leaderboard の相関が取れていることを確認できた。

---

## データ

Kaggle により提供された以下のデータセットを使用した。

* `train.csv` / `test.csv`：店舗 × 商品カテゴリごとの日次販売数
* `stores.csv`：店舗情報（都市、州、店舗タイプ、クラスタ）
* `oil.csv`：日次原油価格（欠損日は補完）
* `holidays_events.csv`：祝日情報（国・地域・ローカル）

特徴量生成の一貫性を保つため、train と test は結合した上で前処理を行い、
**販売数に依存する特徴量は必ず過去データのみを用いて算出**した。

---

## 検証戦略

本プロジェクトにおいて、**精度が大きく向上した最も重要な要因は、交差検証（CV）設計の見直し**である。

### 初期の設計（改善前）

当初は以下のような方法で特徴量を作成していた。

* 移動平均や平均系特徴量（store / family など）を
* **全 fold の中で最も早い `train_end` より前の期間のみ**を用いて算出
* その特徴量を、すべての fold の validation 期間に共通で使用

この方法はリークを防ぐ点では安全である一方で、

* 各 fold の学習期間で利用可能なデータを
* **十分に活用できていない**

という問題があった。

---

### 改善後の設計（最終採用）

精度改善のため、交差検証の設計を以下のように変更した。

* データ分割（fold ループ）の **内側** で特徴量を生成
* 各 fold ごとに

  * `train_end` までの **全データ** を用いて
  * 平均系・移動平均系特徴量を再計算
* validation 期間には、その fold 専用に作成した特徴量を使用

これにより、

* 各 fold において利用可能な過去データを最大限活用
* リークを防ぎつつ、より情報量の多い特徴量を生成

することが可能となった。

---

### 効果

この変更により、

* 交差検証スコアが大幅に改善
* CV と Public Leaderboard の整合性も向上

し、最終的なモデル性能の底上げにつながった。

この経験から、
**時系列タスクにおいては「どのようにデータを分割し、どの時点までの情報を使うか」が
モデル選択以上に重要である**ことを強く認識した。

---|---|---|
| 1 | 2013-01-01 → 2017-06-30 | 2017-07-01 → 2017-07-16 |
| 2 | 2013-01-01 → 2017-07-15 | 2017-07-17 → 2017-08-01 |
| 3 | 2013-01-01 → 2017-07-30 | 2017-07-31 → 2017-08-15 |

すべての fold において、販売実績を用いる特徴量は
`train_end` 以前のデータのみを使用することでリークを防止した。

---

## 特徴量設計

### Fold 非依存の特徴量

* **日付特徴量**：年、月、日、曜日、週末フラグ
* **原油価格特徴量**：移動平均（30 / 90 / 180 日）
* **祝日特徴量**：

  * 国・地域・ローカル祝日フラグ
  * 統合祝日フラグ
  * 特別営業日（Workday）フラグ

### Fold 依存（リーク防止）の特徴量

* **平均系特徴量（Target Encoding）**

  * store / family / store×family / type / cluster
* **販売数の移動平均**

  * window：3 / 7 / 30 日
  * shift を用いて必ず過去値のみを参照

---

## モデル

### ベースモデル：LightGBM

* 目的関数：回帰（log 空間で RMSLE を評価）
* 大規模特徴量に強い勾配ブースティングモデルを採用
* ハイパーパラメータは **Optuna** により最適化

### ハイパーパラメータチューニング

* Optuna + Median Pruner
* 3-fold 時系列交差検証
* 方針：

  1. **CNN なしモデルでフルチューニング**
  2. 得られた best parameter を初期値として利用
  3. CNN 使用時は軽量な探索のみ実施

---

## CNN による時系列 Embedding（検証的実装）

rolling statistics では捉えきれない短期的な時系列パターンを表現するため、
**1D CNN による時系列 embedding** を実装した。

* 入力：過去 30 日間の特徴量

  * promotion フラグ
  * 祝日フラグ
  * 曜日 / 日付
  * 原油価格
* 出力：固定次元の embedding ベクトル
* CNN は **学習せず、特徴抽出器として使用**

計算コスト削減のため、embedding は **fold 単位でキャッシュ**し、
Optuna 実行中に再計算が発生しない設計とした。

### 検証結果と判断

* CNN embedding は特徴量重要度に現れ、モデル内で利用されていた
* train スコアは改善したが、validation スコアの改善は一貫しなかった

以上より、本プロジェクトでは
**再現性・簡潔性・推論コストを優先し、最終モデルでは CNN を不採用**とした。

---

## 最終学習と予測

* 2017-08-15 までの全データを用いて最終モデルを学習
* 2017-08-16 ～ 2017-08-31 を予測対象期間とした
* 提出モデル：

  * 単一最終モデル
  * CV 各 fold モデル＋最終モデルによるアンサンブル

アンサンブルモデルが最良の Public Leaderboard スコアを達成した。

---

## まとめ・学び

* 時系列タスクでは **検証設計が性能を大きく左右する**
* 強力な特徴量設計により、複雑なモデルに頼らず高い性能を達成できる
* 高コスト特徴量（CNN）は **定量評価に基づいて採否を判断すべき**
* モデルの複雑化よりも、再現性と説明可能性を重視した

---

## リポジトリ構成

* `store_sales_new.ipynb` / `.py`：前処理から学習・予測までの一連のコード
* `models/`：fold ごとに学習した LightGBM モデル
* `submission.csv`：単一モデルによる提出ファイル
* `submission_ensemble.csv`：アンサンブル提出ファイル

---

## 補足

本プロジェクトでは、
**精度向上のために複雑なモデルを盲目的に採用するのではなく、
検証結果に基づいて最終判断を行うプロセス**を重視した。

このような意思決定プロセスも含めて、本リポジトリは再現可能な形で公開している。


## ライセンス

このプロジェクトは **MIT ライセンス** の下で公開されています。
詳細は [LICENSE](./LICENSE) ファイルをご覧ください。
